import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tqdm import tqdm
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from scipy.sparse import lil_matrix,csr_matrix
from tensorflow.keras.layers import Embedding

# Reading the Data

### data is taken from https://www.kaggle.com/aiswaryaramachandran/hindienglish-corpora
### data have three column source, english_sentence, hindi_sentence

df=pd.read_csv('Hindi_English_Truncated_Corpus.csv')

## extracting details about data

df.shape

df.info()

## dropping na values

df=df.dropna()

df.shape

## dropping duplicates

df=df.drop_duplicates()

df.shape

df.head()

df['hindi_sentence'].values[124824]

df['hindi_sentence'].values[124824][36]+df['hindi_sentence'].values[124824][37]+df['hindi_sentence'].values[124824][38]

## doing some preprocessing on text data

import re
def preprocess(data_x):
    data1=[]
    for data in tqdm(data_x):
        
        data=data.replace('\\r','').replace('\\n','').replace('\\',' ').replace("n\'t",' not').replace(',',' ')\
        .replace('.',' ').replace('%',' ').replace("'s",' is').replace('-',' ').replace('"','').replace('_','').replace(':','')\
        .replace(';','').replace('!','').replace('!!','').replace(';','').replace('/',' ').replace('?',' ').replace('  ',' ')\
        .replace('ред','')

        p = re.compile('[0-9]+')
        data=p.sub('', data)

        data = re.sub(r"won't", "will not", data)
        data = re.sub(r"can\'t", "can not", data)

        # general
        data = re.sub(r"n\'t", " not", data)
        data = re.sub(r"\'re", " are", data)
        data = re.sub(r"\'s", " is", data)
        data = re.sub(r"\'d", " would", data)
        data = re.sub(r"\'ll", " will", data)
        data = re.sub(r"\'t", " not", data)
        data = re.sub(r"\'ve", " have", data)
        data = re.sub(r"\'m", " am", data)

#         data = ' '.join(e for e in data.split() if e.lower() not in stopwords)
        data=data.lower()
        data=' '.join(data.split())
        data1.append(data)
    return data1
    

df['english_sentence']=preprocess(df['english_sentence'].values)

df.head()

df['hindi_sentence']=preprocess(df['hindi_sentence'].values)

df.head().values

## keeping sentence which have only less than 25 words

keeping_data=[]
for i,val in tqdm(enumerate(df.values)):
    #print(i,val)
    if len(val[1].split(' '))<=25:
        keeping_data.append(val)
    
#     break

len(keeping_data)

df=pd.DataFrame(keeping_data,columns=['source','english_sentence','hindi_sentence'])

df.shape

keeping_data=[]
for i,val in tqdm(enumerate(df.values)):
    #print(i,val)
    if len(val[2].split(' '))<=25:
        keeping_data.append(val)

df=pd.DataFrame(keeping_data,columns=['source','english_sentence','hindi_sentence'])

df.shape

## encoding text so that we can input it in encoder-decoder model

# df['decoder_input_hin']='<start> '+df['hindi_sentence']
df['hindi_sentence']='<start> '+df['hindi_sentence']+' <end>'
df['english_sentence']=df['english_sentence']+' eos'

df.head()

### splitting the data in train and test

from sklearn.model_selection import train_test_split
df=df[['english_sentence','hindi_sentence']]
# y=df['hindi_sentence']
train, test = train_test_split(df, test_size=0.2)

train





t_enc_inp = Tokenizer()
# fit the tokenizer on the documents
sd=t_enc_inp.fit_on_texts(train['english_sentence'].values)

encoded_docs_train = t_enc_inp.texts_to_sequences(train['english_sentence'].values)
encoded_docs_test = t_enc_inp.texts_to_sequences(test['english_sentence'].values)

length=[len(i) for i in encoded_docs_train]

plt.hist(length)

encoder_seq_train = pad_sequences(encoded_docs_train, maxlen=399, dtype='int32', padding='post')
encoder_seq_test = pad_sequences(encoded_docs_test, maxlen=399, dtype='int32', padding='post')
# decoder_out_seq = pad_sequences(encoded_out, maxlen=371, dtype='int32', padding='post')

encoder_seq_train

del encoded_docs_train, encoded_docs_test

## making embded matrix for english text data and for hindi text we will use trainable embedding layer in network itself

embeddings_index = dict()
f = open('D://glove.6B.100d.txt', encoding="utf8")
for line in f:
    values = line.split()
    word = values[0]
    coefs = np.asarray(values[1:], dtype='float32')
    embeddings_index[word] = coefs
f.close()

sd=embeddings_index.get('eos')
print(sd)

eng_inp_vocab_size=max(t_enc_inp.index_word.keys())
embedding_matrix = np.zeros((eng_inp_vocab_size+1, 100))
for word, i in t_enc_inp.word_index.items():
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

embedding_matrix.shape

t_dec_out = Tokenizer()
# fit the tokenizer on the documents
sd=t_dec_out.fit_on_texts(train['hindi_sentence'].values)

encoded_docs_train = t_dec_out.texts_to_sequences(train['hindi_sentence'].values)
# encoded_docs_test = t_dec_out.texts_to_sequences(test['hindi_sentence'].values)

len(t_dec_out.index_word.keys())

vocab_hindi=max(t_dec_out.index_word.keys())

max(t_dec_out.index_word.keys())

length=[len(i) for i in encoded_docs_train]

plt.hist(length)

## making dataloader to inputing input_encoder, input_decoder and output_decoder to model

class Dataset:
    def __init__(self, data, embedding,tokenizer_eng,tokenizer_hin,max_len,vocab_hindi):
        self.encoder_inps = data['english_sentence'].values
#         self.decoder_inps = data['decoder_input_hin'].values
        self.decoder_outs = data['hindi_sentence'].values
        self.embedding = embedding
#         self.embedding1 = embedding1
        self.tknizer_eng = tokenizer_eng
#         self.tknizer_hin_inp = tokenizer_hin_inp
        self.tknizer_hin = tokenizer_hin
        self.max_len = max_len
        self.vocab_hindi=vocab_hindi

    def __getitem__(self, i):
        
        
        
        self.encoder_seq = self.tknizer_eng.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values
#         self.decoder_inp_seq = self.tknizer_hin_inp.texts_to_sequences([self.decoder_inps[i]])
        self.decoder_inp_seq = self.tknizer_hin.texts_to_sequences([self.decoder_outs[i]])
#         print(self.decoder_inp_seq)
        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')
        self.decoder_inp_seq1 = pad_sequences([self.decoder_inp_seq[0][0:len(self.decoder_inp_seq[0])-1]], maxlen=25, dtype='int32', padding='post')
        self.decoder_out_seq = pad_sequences([self.decoder_inp_seq[0][1:]], maxlen=25, dtype='int32', padding='post')
        #print(self.decoder_inp_seq1)
        #print(self.decoder_out_seq)
        #print(self.encoder_seq)
        self.encoder_seq1=[]
        for i in self.encoder_seq[0]:
            self.encoder_seq1.append(self.embedding[i])
        #print(np.array(encoder_seq1).shape)    
        
#         decoder_inp_seq1 =[]
        
#         for i in self.decoder_inp_seq[0]:
#             decoder_inp_seq1.append(self.embedding1[i])
            
#         self.decoder_out_seq1 = np.zeros((25,self.vocab_hindi+1),dtype=np.float32)
        
#         for i,d in enumerate(self.decoder_out_seq[0]):
#             self.decoder_out_seq1[i,d]=1
        
        
        
        #print(self.encoder_seq.shape)
        return np.array(self.encoder_seq1), self.decoder_inp_seq1, self.decoder_out_seq

    def __len__(self): # your model.fit_gen requires this function
        return len(self.encoder_inps)

    
class Dataloder(tf.keras.utils.Sequence):    
    def __init__(self, dataset, batch_size=1):
        #print(dataset)
        self.dataset = dataset
        self.batch_size = batch_size
        self.indexes = np.arange(len(self.dataset.encoder_inps))
        #print(self.indexes)


    def __getitem__(self, i):
        #print(i,'in dataloader')
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            #print(self.dataset[j])
            data.append(self.dataset[j])
            #break
        #print(len(data),'in dataloader')
        batch = [np.stack(samples, axis=0) for samples in zip(*data)]
#         print(batch[2].shape)
        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq
        return tuple([[batch[0],tf.squeeze(batch[1])],batch[2]])

    def __len__(self):  # your model.fit_gen requires this function
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        self.indexes = np.random.permutation(self.indexes)

train_dataset = Dataset(train, embedding_matrix, t_enc_inp,t_dec_out,25,vocab_hindi)
test_dataset  = Dataset(test, embedding_matrix, t_enc_inp,t_dec_out,25,vocab_hindi)

train_dataloader = Dataloder(train_dataset, batch_size=32)
test_dataloader = Dataloder(test_dataset, batch_size=32)
train_dataloader[0]

data=[(np.zeros((399,100)),np.zeros((418,67427)),np.zeros((418,67427))),(np.zeros((399,100)),np.zeros((418,67427)),np.zeros((418,67427)))]
for i in zip(*data):
    print(np.stack(i, axis=0).shape)

## making a simple model

# Define an input sequence and process it.
encoder_inputs = keras.Input(shape=(None, 25))
encoder = keras.layers.LSTM(64, return_state=True)
encoder_outputs, state_h, state_c = encoder(encoder_inputs)

# We discard `encoder_outputs` and only keep the states.
encoder_states = [state_h, state_c]

# Set up the decoder, using `encoder_states` as initial state.
decoder_inputs = keras.Input(shape=(25))
dec_emb_layer = Embedding(vocab_hindi+1,100,input_length=25)(decoder_inputs)
print(dec_emb_layer.shape)

# We set up our decoder to return full output sequences,
# and to return internal states as well. We don't use the
# return states in the training model, but we will use them in inference.
decoder_lstm = keras.layers.LSTM(64, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(dec_emb_layer, initial_state=encoder_states)
decoder_dense = keras.layers.Dense(vocab_hindi+1, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

# Define the model that will turn
# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)

model.summary()

loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True, reduction='none')

def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)

    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask

    return tf.reduce_mean(loss_)

## training the model

model.compile(
    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
)
model.fit(
    train_dataloader,
    epochs=5,
    validation_data=test_dataloader,
    )







# Attention model

class Encoder(tf.keras.Model):
    '''
    Encoder model -- That takes a input sequence and returns output sequence
    '''

    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):
        super().__init__()
        #Initialize Embedding layer
        #Intialize Encoder LSTM layer
        self.inp_vocab_size=inp_vocab_size
        self.embedding_size=embedding_size
        self.lstm_size=lstm_size
        self.input_length=input_length
        
        self.embedding=Embedding(self.inp_vocab_size,self.embedding_size,input_length=self.input_length)
        self.lstm=LSTM(self.lstm_size,return_state=True,return_sequences=True)

    def call(self,input_sequence,states):
      '''
          This function takes a sequence input and the initial states of the encoder.
          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm
          returns -- All encoder_outputs, last time steps hidden and cell state
      '''
      embedding1=self.embedding(input_sequence)
      # print('embedding in encoder---',embedding1.shape)
      self.lstm1,self.h_state,self.c_state=self.lstm(embedding1)
      # print('self.lstm1 in encoder---',self.lstm1.shape)
      # print('self.h_state in encoder---',self.h_state.shape)
      # print('self.c_state in encoder---',self.c_state.shape)
      return self.lstm1,self.h_state,self.c_state

    
    def initialize_states(self,batch_size):
      '''
      Given a batch size it will return intial hidden state and intial cell state.
      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]
      '''
      self.hid_state=np.zeros((batch_size,self.lstm_size))
      self.cell_state=np.zeros((batch_size,self.lstm_size))
      return self.hid_state,self.cell_state
      

class Attention(tf.keras.layers.Layer):
  '''
    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.
  '''
  def __init__(self,scoring_function, att_units):
    super().__init__()

    # Please go through the reference notebook and research paper to complete the scoring functions
    self.att_units=att_units
    self.scoring_function=scoring_function
    if self.scoring_function=='dot':
      # Intialize variables needed for Dot score function here
      # self.softmax=Softmax(axis=1)
      pass

      
      
    if scoring_function == 'general':
      # Intialize variables needed for General score function here
      self.dense1=Dense(self.att_units,activation=None)
      # self.softmax1=Softmax(axis=1)
      
    elif scoring_function == 'concat':
      # Intialize variables needed for Concat score function here
      self.dense2=Dense(self.att_units,activation=None)
      self.dense3=Dense(self.att_units,activation=None)
      self.dense4=Dense(1,activation=None)
      
  
  
  def call(self,decoder_hidden_state,encoder_output):
    '''
      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.
      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.
        Multiply the score function with your encoder_outputs to get the context vector.
        Function returns context vector and attention weights(softmax - scores)
    '''
    decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=1)
    if self.scoring_function == 'dot':
        score = tf.matmul(decoder_hidden_state, encoder_output, transpose_b=True)
        # print(score.shape,'score')
        score = tf.transpose(score,[0,2,1])
        # print(score.shape,'score')
        attention_weights = tf.math.softmax(score,axis=1)
        # print(attention_weights.shape,'attention_weights')
        
        
        # print(encoder_output.shape,'encoder_output')
        # print(decoder_hidden_state.shape,'decoder_hidden_state')
        
        
        # print(attention_weights.shape,'attention_weights')
        context_vector=tf.matmul(attention_weights,encoder_output, transpose_a=True)
        # print(context_vector.shape,'context_vector')
        # context_vector = tf.transpose(context_vector,[0,2,1])
        # print(context_vector.shape,'context_vector')
        context_vector=tf.squeeze(context_vector,axis=1)
        # print(context_vector.shape,'context_vector')
        
          
        
        return context_vector,attention_weights

        
    elif self.scoring_function == 'general':
        
        output1=self.dense1(encoder_output)
        score = tf.matmul(output1,decoder_hidden_state, transpose_b=True)
        # score = tf.transpose(score,[0,2,1])
        # print(score.shape,'score')
        attention_weights = tf.math.softmax(score,axis=1)
        context_vector=tf.matmul(attention_weights,encoder_output, transpose_a=True)
        #context_vector = tf.transpose(context_vector,[0,2,1])
        context_vector=tf.squeeze(context_vector,axis=1)
          
        return context_vector,attention_weights

    
    elif self.scoring_function == 'concat':
    #     # Implement General score function here
          concat1=self.dense2(encoder_output)
          concat2=self.dense3(decoder_hidden_state)
          # concat2=tf.repeat(concat2,)
          concat1=tf.transpose(concat1,[1,0,2])
          concat2=tf.transpose(concat2,[1,0,2])
          # print(concat1.shape,concat2.shape)
          #concat = tf.map_fn(lambda x: tf.add(x, concat2), concat1)
          concat=tf.transpose(tf.multiply(concat2,concat1),[1,0,2])
          concat=tf.math.tanh(concat)
          attention_weights=self.dense4(concat)
          # print(attention_weights.shape)
          context_vector=tf.matmul(attention_weights,encoder_output, transpose_a=True)
          #context_vector = tf.transpose(context_vector,[0,2,1])
          context_vector=tf.squeeze(context_vector,axis=1)
          # print(context_vector.shape,'context_vector')
          return context_vector,attention_weights
    
    

class One_Step_Decoder(tf.keras.Model):
  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):

      # Initialize decoder embedding layer, LSTM and any other objects needed
      super().__init__()
      #Initialize Embedding layer
      #Intialize Encoder LSTM layer
      self.inp_vocab_size=tar_vocab_size
      self.embedding_size=embedding_dim
      self.lstm_size=dec_units
      self.input_length=input_length
      self.att_units=att_units
      self.score_fun=score_fun
      
      self.embedding=Embedding(self.inp_vocab_size,self.embedding_size,input_length=self.input_length)
      self.lstm=LSTM(self.lstm_size,return_state=True,return_sequences=True)
      self.attention=Attention(self.score_fun,self.att_units)
      self.dense=Dense(self.inp_vocab_size,activation='relu')
      self.concat=tf.keras.layers.Concatenate()


  def call(self,input_to_decoder, encoder_output, state_h,state_c):
    '''
        One step decoder mechanisim step by step:
      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)
      B. Using the encoder_output and decoder hidden state, compute the context vector.
      C. Concat the context vector with the step A output
      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)
      E. Pass the decoder output to dense layer(vocab size) and store the result into output.
      F. Return the states from step D, output from Step E, attention weights from Step -B

    '''
    embedding_out=self.embedding(input_to_decoder)
    
    self.context_vector,self.attention_weights=self.attention(state_h,encoder_output)
    
    concat_vec=self.concat((embedding_out,tf.expand_dims(self.context_vector,axis=1)))
    
    self.lstm1,self.h_state,self.c_state=self.lstm(concat_vec,initial_state=[state_h,state_c])
    #print(self.lstm1.shape,'self.lstm1.shape')
    output=self.dense(self.lstm1)
    #print(output.shape,'output.shape')
    output=tf.squeeze(output,axis=1)
    #print(output.shape,'output.shape')
    
    return output,self.h_state,self.c_state,self.attention_weights,self.context_vector



class Decoder(tf.keras.Model):
    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):
      #Intialize necessary variables and create an object from the class onestepdecoder
      super().__init__()
      #Initialize Embedding layer
      #Intialize Encoder LSTM layer
      self.inp_vocab_size=out_vocab_size
      self.embedding_dim=embedding_dim
      self.lstm_size=dec_units
      self.input_length=input_length
      self.att_units=att_units
      self.score_fun=score_fun

      self.onestepdecoder=One_Step_Decoder(self.inp_vocab_size, self.embedding_dim, self.input_length, self.lstm_size ,self.score_fun ,self.att_units)



        
    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):

        #Initialize an empty Tensor array, that will store the outputs at each and every time step
        #Create a tensor array as shown in the reference notebook
        # print(input_to_decoder.shape,'input_to_decoder.shape')
        all_outputs=tf.TensorArray(tf.float32,tf.shape(input_to_decoder)[1],name='output_arrays')
        #print(input_to_decoder.shape,'input_to_decoder')
        for i in range(tf.shape(input_to_decoder)[1]):
          # print(input_to_decoder[:,i:i+1],'input_to_decoder[:,i:i+1]')
          output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,i:i+1],encoder_output,decoder_hidden_state,decoder_cell_state)
          all_outputs=all_outputs.write(i,output)
        # print(np.array(all_outputs).shape,'np.array(all_outputs).shape')  
        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])  
        # print(all_outputs.shape,'all_outputs.shape')  
        return all_outputs
        
        #Iterate till the length of the decoder input
            # Call onestepdecoder for each token in decoder_input
            # Store the output in tensorarray
        # Return the tensor array
        

class encoder_decoder(tf.keras.Model):
  def __init__(self,inp_vocab_size,embedding_size,lstm_size,encoder_input_length,out_vocab_size, decoder_input_length, dec_units ,score_fun ,att_units):

    # self,out_vocab_size, decoder_input_length, dec_units ,score_fun ,att_units
    #Intialize objects from encoder decoder
    super().__init__()
    #Create encoder object
    #Create decoder object
    #Intialize Dense layer(out_vocab_size) with activation='softmax'
    # self.embedding=Embedding(out_vocab_size,embedding_size,input_length=decoder_input_length)
    self.encoder=Encoder(inp_vocab_size,embedding_size=embedding_size,lstm_size=lstm_size,input_length=encoder_input_length)
    self.decoder=Decoder(out_vocab_size,embedding_dim=embedding_size,input_length=decoder_input_length,dec_units=dec_units,score_fun=score_fun,att_units=att_units)
    
    # self.dense=Dense(output_length,activation='softmax')
    
  def call(self,data):
    input,output=data[0],data[1]
    #print(input[0])

    #print('Input---',input.shape)
    #print('output---',output.shape)
    
    enc_output, encoder_h, encoder_c=self.encoder(input,'kjl')

    # print('enc_output---',enc_output.shape)
    # print('encoder_h---',encoder_h.shape)
    # print('encoder_c---',encoder_c.shape)

    # embeddings1=self.embedding(enc_output)

    # print('embeddings1----',embeddings1.shape)

    decoder_output=self.decoder(output,enc_output,encoder_h,encoder_c)
    
    # print('decoder_output---',decoder_output.shape)

    return decoder_output
    #Intialize encoder states, Pass the encoder_sequence to the embedding layer
    # Decoder initial states are encoder final states, Initialize it accordingly
    # Pass the decoder sequence,encoder_output,decoder states to Decoder
    # return the decoder output



